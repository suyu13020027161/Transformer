{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeMl7NbXJ0MF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# preprocessing + train-only selection + baselines\n",
        "# ============================================================\n",
        "import re, math, numpy as np, pandas as pd\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "from sklearn.cross_decomposition import PLSRegression\n",
        "\n",
        "from scipy.signal import savgol_filter\n",
        "warnings.filter('ignore')\n",
        "\n",
        "# -----------------------\n",
        "# Config\n",
        "# -----------------------\n",
        "CSV_PATH   = \"input_updated_v10_YC_1.csv\"\n",
        "TARGET_COL = \"Nmass_O\"\n",
        "\n",
        "WAVELEN_MIN = 400.0\n",
        "WAVELEN_MAX = 2400.0\n",
        "\n",
        "# Remove strong water absorption windows (nanometres)\n",
        "WATER_BANDS = None\n",
        "\n",
        "\n",
        "# Savitzky–Golay (for 1st derivative)\n",
        "SG_WINDOW   = 15   # must be odd; try 11, 15, 21\n",
        "SG_POLY     = 2\n",
        "SG_DERIV    = 1    # first derivative\n",
        "\n",
        "# Selection limits\n",
        "K_MIN = 8\n",
        "K_MAX = 40\n",
        "INNER_KFOLDS = 5          # for inner CV when choosing k / components\n",
        "MIN_SPACING_NM = 12.0     # enforce spacing for sSPA picked bands\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "TEST_SIZE = 0.15\n",
        "VAL_SIZE  = 0.15  # of full dataset (train gets 1 - TEST - VAL)\n",
        "\n",
        "# -----------------------\n",
        "# Utils\n",
        "# -----------------------\n",
        "def nm_from_col(name: str):\n",
        "    m = re.findall(r\"(\\d+(?:\\.\\d+)?)\", str(name))\n",
        "    return float(m[-1]) if m else np.nan\n",
        "\n",
        "def snv_transform(X):\n",
        "    # Standard Normal Variate per spectrum (row-wise)\n",
        "    mu = X.mean(axis=1, keepdims=True)\n",
        "    sd = X.std(axis=1, keepdims=True) + 1e-12\n",
        "    return (X - mu) / sd\n",
        "\n",
        "def remove_water_bands(wls_nm, X):\n",
        "    mask = np.ones_like(wls_nm, dtype=bool)\n",
        "    for lo, hi in WATER_BANDS:\n",
        "        mask &= ~((wls_nm >= lo) & (wls_nm <= hi))\n",
        "    return wls_nm[mask], X[:, mask], mask\n",
        "\n",
        "def rmse(y_true, y_pred):\n",
        "    return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
        "\n",
        "# -----------------------\n",
        "# Preprocess: band windowing (400–2400), water windows, SG deriv + SNV\n",
        "# -----------------------\n",
        "def spectral_preprocess(X_raw, wls_nm_raw):\n",
        "    # 1) keep 400–2400\n",
        "    mask = (wls_nm_raw >= WAVELEN_MIN) & (wls_nm_raw <= WAVELEN_MAX) & np.isfinite(wls_nm_raw)\n",
        "    wls = wls_nm_raw[mask]\n",
        "    X   = X_raw[:, mask]\n",
        "\n",
        "    # 2) Savitzky–Golay first derivative (along spectral axis)\n",
        "    #    If window > #bands, shrink window\n",
        "    window = SG_WINDOW if SG_WINDOW < X.shape[1] else (X.shape[1] - (1 - X.shape[1] % 2))\n",
        "    window = max(5, window if window % 2 == 1 else window - 1)\n",
        "    X_sg = savgol_filter(X, window_length=window, polyorder=SG_POLY, deriv=SG_DERIV, axis=1)\n",
        "\n",
        "    # 3) remove water windows AFTER derivative (either before or after works; be consistent)\n",
        "    wls2, X2, mask2 = remove_water_bands(wls, X_sg)\n",
        "\n",
        "    # 4) SNV per spectrum\n",
        "    X2 = snv_transform(X2)\n",
        "\n",
        "    return X2.astype(np.float32), wls2\n",
        "\n",
        "# -----------------------\n",
        "# sSPA (supervised) with train-only fit + min spacing\n",
        "# -----------------------\n",
        "def corr_abs(a, b):\n",
        "    a = a - a.mean(); b = b - b.mean()\n",
        "    sa, sb = a.std() + 1e-12, b.std() + 1e-12\n",
        "    return abs(np.dot(a/sa, b/sb) / len(a))\n",
        "\n",
        "def supervised_spa_order_trainonly(Xtr, ytr, wls_nm, max_k=40, first=\"maxcorr\", min_spacing_nm=None, verbose=False):\n",
        "    \"\"\"\n",
        "    Compute sSPA order on TRAIN ONLY, with optional min-spacing constraint.\n",
        "    \"\"\"\n",
        "    N, P = Xtr.shape\n",
        "    # Start band\n",
        "    if first == \"maxcorr\":\n",
        "        cors = [corr_abs(Xtr[:, j], ytr) for j in range(P)]\n",
        "        j0 = int(np.argmax(cors))\n",
        "    elif first == \"maxnorm\":\n",
        "        j0 = int(np.argmax(np.linalg.norm(Xtr, axis=0)))\n",
        "    else:\n",
        "        rng = np.random.default_rng(RANDOM_STATE); j0 = int(rng.integers(0, P))\n",
        "\n",
        "    chosen = [j0]\n",
        "    if verbose:\n",
        "        print(f\"[sSPA] m=1 → idx={j0} (~{wls_nm[j0]:.0f} nm)\")\n",
        "\n",
        "    def too_close(j):\n",
        "        if min_spacing_nm is None or min_spacing_nm <= 0: return False\n",
        "        for c in chosen:\n",
        "            if abs(wls_nm[j] - wls_nm[c]) < min_spacing_nm:\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    for m in range(2, max_k+1):\n",
        "        Xk = Xtr[:, chosen]\n",
        "        best_j, best_score, best_norm = None, -1.0, None\n",
        "        for j in range(P):\n",
        "            if j in chosen: continue\n",
        "            if too_close(j): continue\n",
        "            xj = Xtr[:, j]\n",
        "            if Xk.ndim == 1 or Xk.shape[1] == 0:\n",
        "                rj = xj\n",
        "            else:\n",
        "                beta, *_ = np.linalg.lstsq(Xk, xj, rcond=None)\n",
        "                rj = xj - Xk @ beta\n",
        "            rn = np.linalg.norm(rj)\n",
        "            sc = 0.0 if rn < 1e-12 else rn * corr_abs(rj, ytr)\n",
        "            if sc > best_score:\n",
        "                best_score, best_j, best_norm = sc, j, rn\n",
        "        if best_j is None:\n",
        "            if verbose: print(f\"[sSPA] stopped early at m={m-1} (spacing/exhausted)\")\n",
        "            break\n",
        "        chosen.append(best_j)\n",
        "        if verbose and (m <= 5 or m % 5 == 0):\n",
        "            print(f\"[sSPA] m={m} → idx={best_j} (~{wls_nm[best_j]:.0f} nm)  score={best_score:.4g}  ||res||={best_norm:.4g}\")\n",
        "    return chosen\n",
        "\n",
        "def choose_k_via_inner_cv(Xtr, ytr, order, k_min=8, k_max=40, inner_folds=5, base_model=\"ridge\"):\n",
        "    \"\"\"\n",
        "    Inner CV ONLY ON TRAIN to choose k. base_model ∈ {\"linreg\",\"ridge\"}.\n",
        "    \"\"\"\n",
        "    k_max = min(k_max, len(order))\n",
        "    ks = list(range(k_min, k_max+1))\n",
        "    kf = KFold(n_splits=inner_folds, shuffle=True, random_state=RANDOM_STATE)\n",
        "    mean_rmse = []\n",
        "\n",
        "    for k in ks:\n",
        "        cols = order[:k]\n",
        "        fold_err = []\n",
        "        for tr, va in kf.split(Xtr):\n",
        "            X_tr, X_va = Xtr[tr][:, cols], Xtr[va][:, cols]\n",
        "            y_tr, y_va = ytr[tr], ytr[va]\n",
        "            # Scale inside CV\n",
        "            sc = StandardScaler().fit(X_tr)\n",
        "            X_tr_s = sc.transform(X_tr)\n",
        "            X_va_s = sc.transform(X_va)\n",
        "            if base_model == \"linreg\":\n",
        "                mdl = LinearRegression()\n",
        "            else:\n",
        "                # RidgeCV inside each fold to stabilise (fast)\n",
        "                mdl = RidgeCV(alphas=np.logspace(-4, 3, 20), store_cv_values=False)\n",
        "            mdl.fit(X_tr_s, y_tr)\n",
        "            y_hat = mdl.predict(X_va_s)\n",
        "            fold_err.append(rmse(y_va, y_hat))\n",
        "        mean_rmse.append(np.mean(fold_err))\n",
        "    k_best = ks[int(np.argmin(mean_rmse))]\n",
        "    return k_best, mean_rmse\n",
        "\n",
        "# -----------------------\n",
        "# Alternative selectors (MI, LassoCV)\n",
        "# -----------------------\n",
        "def mi_rank(Xtr, ytr):\n",
        "    mi = mutual_info_regression(Xtr, ytr, random_state=RANDOM_STATE)\n",
        "    return list(np.argsort(mi)[::-1])  # descending\n",
        "\n",
        "def lasso_select(Xtr, ytr):\n",
        "    # LassoCV chooses alpha with CV; we rank by |coef| and keep non-zeros\n",
        "    sc = StandardScaler().fit(Xtr)\n",
        "    Xtr_s = sc.transform(Xtr)\n",
        "    lcv = LassoCV(alphas=None, cv=INNER_KFOLDS, random_state=RANDOM_STATE, max_iter=20000).fit(Xtr_s, ytr)\n",
        "    coef = np.abs(lcv.coef_)\n",
        "    order = list(np.argsort(coef)[::-1])\n",
        "    sel = [j for j in order if coef[j] > 1e-9]\n",
        "    return sel, lcv.alpha_\n",
        "\n",
        "# -----------------------\n",
        "# Baselines on selected bands (PLSR, Ridge)\n",
        "# -----------------------\n",
        "def run_plsr_trainval_test(X_tr, y_tr, X_va, y_va, X_te, y_te, ncomp_min=4, ncomp_max=24):\n",
        "    \"\"\"\n",
        "    Fit PLSR with components chosen by inner CV on TRAIN only, then refit on TRAIN+VAL and test.\n",
        "    \"\"\"\n",
        "    kf = KFold(n_splits=INNER_KFOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
        "    comps = list(range(ncomp_min, ncomp_max+1))\n",
        "    mean_rmse = []\n",
        "    for c in comps:\n",
        "        fold_err = []\n",
        "        for tr, va in kf.split(X_tr):\n",
        "            sc = StandardScaler().fit(X_tr[tr])\n",
        "            Xtr_s = sc.transform(X_tr[tr]); Xva_s = sc.transform(X_tr[va])\n",
        "            pls = PLSRegression(n_components=c)\n",
        "            pls.fit(Xtr_s, y_tr[tr])\n",
        "            y_hat = pls.predict(Xva_s).ravel()\n",
        "            fold_err.append(rmse(y_tr[va], y_hat))\n",
        "        mean_rmse.append(np.mean(fold_err))\n",
        "    c_best = comps[int(np.argmin(mean_rmse))]\n",
        "    # Refit on TRAIN+VAL, test\n",
        "    X_tv = np.vstack([X_tr, X_va]); y_tv = np.concatenate([y_tr, y_va])\n",
        "    sc2 = StandardScaler().fit(X_tv)\n",
        "    pls2 = PLSRegression(n_components=c_best).fit(sc2.transform(X_tv), y_tv)\n",
        "    y_pred = pls2.predict(sc2.transform(X_te)).ravel()\n",
        "    return {\"n_components\": c_best,\n",
        "            \"rmse\": rmse(y_te, y_pred),\n",
        "            \"r2\": r2_score(y_te, y_pred),\n",
        "            \"pred\": y_pred}\n",
        "\n",
        "def run_ridge_trainval_test(X_tr, y_tr, X_va, y_va, X_te, y_te):\n",
        "    \"\"\"\n",
        "    RidgeCV on TRAIN via inner CV, then refit on TRAIN+VAL and test.\n",
        "    \"\"\"\n",
        "    alphas = np.logspace(-4, 3, 60)\n",
        "    sc = StandardScaler().fit(X_tr)\n",
        "    Xtr_s = sc.transform(X_tr); Xva_s = sc.transform(X_va)\n",
        "    ridge = RidgeCV(alphas=alphas, cv=INNER_KFOLDS).fit(np.vstack([Xtr_s, Xva_s]),\n",
        "                                                        np.concatenate([y_tr, y_va]))\n",
        "    sc_all = StandardScaler().fit(np.vstack([X_tr, X_va]))\n",
        "    y_pred = ridge.predict(sc_all.transform(X_te))\n",
        "    return {\"alpha\": float(ridge.alpha_),\n",
        "            \"rmse\": rmse(y_te, y_pred),\n",
        "            \"r2\": r2_score(y_te, y_pred),\n",
        "            \"pred\": y_pred}\n",
        "\n",
        "# -----------------------\n",
        "# Load data, preprocess, split\n",
        "# -----------------------\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "all_band_cols = [c for c in df.columns if \"wave\" in c.lower()]\n",
        "wls_nm_all = np.array([nm_from_col(c) for c in all_band_cols], dtype=float)\n",
        "\n",
        "df = df[[TARGET_COL] + all_band_cols].dropna().reset_index(drop=True)\n",
        "X_raw = df[all_band_cols].to_numpy(dtype=float)\n",
        "y     = df[TARGET_COL].to_numpy(dtype=float)\n",
        "\n",
        "# Preprocess spectra (SG deriv + water removal + SNV)\n",
        "X_pp, wls_pp = spectral_preprocess(X_raw, wls_nm_all)\n",
        "\n",
        "# Consistent split: 70/15/15 (train/val/test)\n",
        "X_tv, X_te, y_tv, y_te = train_test_split(X_pp, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, shuffle=True)\n",
        "val_ratio_in_tv = VAL_SIZE / (1.0 - TEST_SIZE)\n",
        "X_tr, X_va, y_tr, y_va = train_test_split(X_tv, y_tv, test_size=val_ratio_in_tv, random_state=RANDOM_STATE, shuffle=True)\n",
        "\n",
        "print(f\"Split → train={len(y_tr)} | valid={len(y_va)} | test={len(y_te)} | bands={X_pp.shape[1]}\")\n",
        "\n",
        "# -----------------------\n",
        "# Train-only sSPA with spacing -> choose k by inner CV -> lock bands\n",
        "# -----------------------\n",
        "order_sspa = supervised_spa_order_trainonly(\n",
        "    X_tr, y_tr, wls_pp,\n",
        "    max_k=K_MAX, first=\"maxcorr\", min_spacing_nm=MIN_SPACING_NM, verbose=True\n",
        ")\n",
        "\n",
        "k_best, curve = choose_k_via_inner_cv(\n",
        "    X_tr, y_tr, order_sspa,\n",
        "    k_min=K_MIN, k_max=K_MAX, inner_folds=INNER_KFOLDS, base_model=\"ridge\"\n",
        ")\n",
        "\n",
        "sel_cols = order_sspa[:k_best]\n",
        "sel_wls  = [float(wls_pp[j]) for j in sel_cols]\n",
        "\n",
        "print(f\"\\n[sSPA] Inner-CV best k = {k_best}\")\n",
        "print(\"Selected wavelengths (nm):\", [int(round(w)) for w in sel_wls])\n",
        "\n",
        "# Slice datasets to selected bands\n",
        "Xtr_sel = X_tr[:, sel_cols]; Xva_sel = X_va[:, sel_cols]; Xte_sel = X_te[:, sel_cols]\n",
        "\n",
        "# -----------------------\n",
        "# Baselines on selected bands\n",
        "# -----------------------\n",
        "res_plsr  = run_plsr_trainval_test(Xtr_sel, y_tr, Xva_sel, y_va, Xte_sel, y_te, ncomp_min=4, ncomp_max=min(24, k_best))\n",
        "res_ridge = run_ridge_trainval_test(Xtr_sel, y_tr, Xva_sel, y_va, Xte_sel, y_te)\n",
        "\n",
        "print(\"\\n=== Baselines on train-only selected bands ===\")\n",
        "print(f\"PLSR  → comps={res_plsr['n_components']:>2} | Test RMSE={res_plsr['rmse']:.3f} | Test R²={res_plsr['r2']:.3f}\")\n",
        "print(f\"Ridge → alpha={res_ridge['alpha']:.4g} | Test RMSE={res_ridge['rmse']:.3f} | Test R²={res_ridge['r2']:.3f}\")\n",
        "\n",
        "# -----------------------\n",
        "# Alternative selectors for comparison\n",
        "# -----------------------\n",
        "# 1) Mutual Information ranking (train only), pick k via inner CV\n",
        "mi_order = mi_rank(Xtr_sel if Xtr_sel.shape[1] > 0 else X_tr, y_tr)  # safe fallback\n",
        "if len(mi_order) > 0:\n",
        "    base_X = Xtr_sel if Xtr_sel.shape[1] > 0 else X_tr\n",
        "    k_best_mi, _ = choose_k_via_inner_cv(base_X, y_tr, mi_order, k_min=min(K_MIN, len(mi_order)), k_max=min(K_MAX, len(mi_order)))\n",
        "    cols_mi = mi_order[:k_best_mi]\n",
        "    # Map to wavelengths if using whole space\n",
        "    if base_X is X_tr:\n",
        "        wls_mi = [int(round(wls_pp[j])) for j in cols_mi]\n",
        "        print(f\"\\n[MI] best k={k_best_mi} | wls(nm)={wls_mi}\")\n",
        "        Xtr_mi, Xva_mi, Xte_mi = X_tr[:, cols_mi], X_va[:, cols_mi], X_te[:, cols_mi]\n",
        "    else:\n",
        "        # if we ranked within selected subset, keep as is\n",
        "        Xtr_mi, Xva_mi, Xte_mi = Xtr_sel[:, cols_mi], Xva_sel[:, cols_mi], Xte_sel[:, cols_mi]\n",
        "    res_plsr_mi  = run_plsr_trainval_test(Xtr_mi, y_tr, Xva_mi, y_va, Xte_mi, y_te, ncomp_min=2, ncomp_max=min(20, Xtr_mi.shape[1]))\n",
        "    res_ridge_mi = run_ridge_trainval_test(Xtr_mi, y_tr, Xva_mi, y_va, Xte_mi, y_te)\n",
        "    print(f\"[MI]  PLSR  Test R²={res_plsr_mi['r2']:.3f} | RMSE={res_plsr_mi['rmse']:.3f}\")\n",
        "    print(f\"[MI]  Ridge Test R²={res_ridge_mi['r2']:.3f} | RMSE={res_ridge_mi['rmse']:.3f}\")\n",
        "\n",
        "# 2) LassoCV selection (train only)\n",
        "order_lasso, alpha_lasso = lasso_select(X_tr, y_tr)\n",
        "if len(order_lasso) > 0:\n",
        "    k_lasso = min(K_MAX, max(K_MIN, len(order_lasso)))\n",
        "    cols_lasso = order_lasso[:k_lasso]\n",
        "    print(f\"\\n[LassoCV] α={alpha_lasso:.4g} | selected={len(order_lasso)} → using first {k_lasso}\")\n",
        "    print(\"[LassoCV] wls(nm)=\", [int(round(wls_pp[j])) for j in cols_lasso])\n",
        "    Xtr_la, Xva_la, Xte_la = X_tr[:, cols_lasso], X_va[:, cols_lasso], X_te[:, cols_lasso]\n",
        "    res_plsr_la  = run_plsr_trainval_test(Xtr_la, y_tr, Xva_la, y_va, Xte_la, y_te, ncomp_min=2, ncomp_max=min(20, Xtr_la.shape[1]))\n",
        "    res_ridge_la = run_ridge_trainval_test(Xtr_la, y_tr, Xva_la, y_va, Xte_la, y_te)\n",
        "    print(f\"[Lasso] PLSR  Test R²={res_plsr_la['r2']:.3f} | RMSE={res_plsr_la['rmse']:.3f}\")\n",
        "    print(f\"[Lasso] Ridge Test R²={res_ridge_la['r2']:.3f} | RMSE={res_ridge_la['rmse']:.3f}\")\n",
        "\n",
        "# -----------------------\n",
        "# Export table of selected bands (sSPA)\n",
        "# -----------------------\n",
        "sel_table = pd.DataFrame({\n",
        "    \"rank\": np.arange(1, len(sel_cols)+1),\n",
        "    \"col_index\": sel_cols,\n",
        "    \"wavelength_nm\": sel_wls\n",
        "})\n",
        "print(\"\\nTrain-only sSPA selected bands:\")\n",
        "display(sel_table)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JwOt_gCUHvfs",
        "outputId": "e7a80b0a-b8c6-4179-c7e9-cf356b9f595b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split → train=2151 | valid=461 | test=462 | bands=1739\n",
            "[sSPA] m=1 → idx=300 (~700 nm)\n",
            "[sSPA] m=2 → idx=326 (~726 nm)  score=74.54  ||res||=100.6\n",
            "[sSPA] m=3 → idx=288 (~688 nm)  score=2.058  ||res||=20.09\n",
            "[sSPA] m=4 → idx=7 (~407 nm)  score=0.7301  ||res||=8.719\n",
            "[sSPA] m=5 → idx=19 (~419 nm)  score=0.5465  ||res||=8.391\n",
            "[sSPA] m=10 → idx=926 (~1326 nm)  score=0.2527  ||res||=2.398\n",
            "[sSPA] m=15 → idx=1474 (~2136 nm)  score=0.1422  ||res||=0.6937\n",
            "[sSPA] m=20 → idx=1516 (~2178 nm)  score=0.06135  ||res||=0.8446\n",
            "[sSPA] m=25 → idx=1540 (~2202 nm)  score=0.04556  ||res||=0.7601\n",
            "[sSPA] m=30 → idx=1396 (~2058 nm)  score=0.02982  ||res||=0.801\n",
            "[sSPA] m=35 → idx=272 (~672 nm)  score=0.03594  ||res||=1.378\n",
            "[sSPA] m=40 → idx=236 (~636 nm)  score=0.0241  ||res||=1.042\n",
            "\n",
            "[sSPA] Inner-CV best k = 40\n",
            "Selected wavelengths (nm): [700, 726, 688, 407, 419, 2253, 442, 2070, 509, 1326, 712, 557, 748, 531, 2136, 454, 2148, 2190, 2358, 2178, 569, 2160, 2241, 2384, 2202, 1344, 1727, 767, 1022, 2058, 2400, 2299, 470, 930, 672, 2228, 1149, 1475, 962, 636]\n",
            "\n",
            "=== Baselines on train-only selected bands ===\n",
            "PLSR  → comps=23 | Test RMSE=3.740 | Test R²=0.747\n",
            "Ridge → alpha=0.3625 | Test RMSE=3.722 | Test R²=0.750\n",
            "[MI]  PLSR  Test R²=0.746 | RMSE=3.748\n",
            "[MI]  Ridge Test R²=0.750 | RMSE=3.722\n",
            "\n",
            "[LassoCV] α=0.021 | selected=171 → using first 40\n",
            "[LassoCV] wls(nm)= [1727, 627, 1675, 1538, 2136, 1757, 1187, 1607, 1476, 1031, 1720, 1635, 1010, 952, 2255, 2157, 2149, 2147, 1073, 849, 772, 712, 2244, 2198, 1283, 882, 1991, 2191, 2186, 2070, 2205, 2108, 2039, 906, 1625, 2223, 1708, 2177, 2179, 957]\n",
            "[Lasso] PLSR  Test R²=0.738 | RMSE=3.810\n",
            "[Lasso] Ridge Test R²=0.738 | RMSE=3.804\n",
            "\n",
            "Train-only sSPA selected bands:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    rank  col_index  wavelength_nm\n",
              "0      1        300          700.0\n",
              "1      2        326          726.0\n",
              "2      3        288          688.0\n",
              "3      4          7          407.0\n",
              "4      5         19          419.0\n",
              "5      6       1591         2253.0\n",
              "6      7         42          442.0\n",
              "7      8       1408         2070.0\n",
              "8      9        109          509.0\n",
              "9     10        926         1326.0\n",
              "10    11        312          712.0\n",
              "11    12        157          557.0\n",
              "12    13        348          748.0\n",
              "13    14        131          531.0\n",
              "14    15       1474         2136.0\n",
              "15    16         54          454.0\n",
              "16    17       1486         2148.0\n",
              "17    18       1528         2190.0\n",
              "18    19       1696         2358.0\n",
              "19    20       1516         2178.0\n",
              "20    21        169          569.0\n",
              "21    22       1498         2160.0\n",
              "22    23       1579         2241.0\n",
              "23    24       1722         2384.0\n",
              "24    25       1540         2202.0\n",
              "25    26        944         1344.0\n",
              "26    27       1226         1727.0\n",
              "27    28        367          767.0\n",
              "28    29        622         1022.0\n",
              "29    30       1396         2058.0\n",
              "30    31       1738         2400.0\n",
              "31    32       1637         2299.0\n",
              "32    33         70          470.0\n",
              "33    34        530          930.0\n",
              "34    35        272          672.0\n",
              "35    36       1566         2228.0\n",
              "36    37        749         1149.0\n",
              "37    38        974         1475.0\n",
              "38    39        562          962.0\n",
              "39    40        236          636.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4a18e483-8497-42f0-a26d-c511a7e1eab9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rank</th>\n",
              "      <th>col_index</th>\n",
              "      <th>wavelength_nm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>300</td>\n",
              "      <td>700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>326</td>\n",
              "      <td>726.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>288</td>\n",
              "      <td>688.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>407.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>19</td>\n",
              "      <td>419.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>1591</td>\n",
              "      <td>2253.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>42</td>\n",
              "      <td>442.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>1408</td>\n",
              "      <td>2070.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>109</td>\n",
              "      <td>509.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>926</td>\n",
              "      <td>1326.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>312</td>\n",
              "      <td>712.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>157</td>\n",
              "      <td>557.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>348</td>\n",
              "      <td>748.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>131</td>\n",
              "      <td>531.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>1474</td>\n",
              "      <td>2136.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>16</td>\n",
              "      <td>54</td>\n",
              "      <td>454.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>17</td>\n",
              "      <td>1486</td>\n",
              "      <td>2148.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>18</td>\n",
              "      <td>1528</td>\n",
              "      <td>2190.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>19</td>\n",
              "      <td>1696</td>\n",
              "      <td>2358.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>20</td>\n",
              "      <td>1516</td>\n",
              "      <td>2178.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>21</td>\n",
              "      <td>169</td>\n",
              "      <td>569.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>22</td>\n",
              "      <td>1498</td>\n",
              "      <td>2160.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>23</td>\n",
              "      <td>1579</td>\n",
              "      <td>2241.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>24</td>\n",
              "      <td>1722</td>\n",
              "      <td>2384.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>25</td>\n",
              "      <td>1540</td>\n",
              "      <td>2202.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>26</td>\n",
              "      <td>944</td>\n",
              "      <td>1344.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>27</td>\n",
              "      <td>1226</td>\n",
              "      <td>1727.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>28</td>\n",
              "      <td>367</td>\n",
              "      <td>767.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>29</td>\n",
              "      <td>622</td>\n",
              "      <td>1022.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>30</td>\n",
              "      <td>1396</td>\n",
              "      <td>2058.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>31</td>\n",
              "      <td>1738</td>\n",
              "      <td>2400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>32</td>\n",
              "      <td>1637</td>\n",
              "      <td>2299.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>33</td>\n",
              "      <td>70</td>\n",
              "      <td>470.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>34</td>\n",
              "      <td>530</td>\n",
              "      <td>930.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>35</td>\n",
              "      <td>272</td>\n",
              "      <td>672.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>36</td>\n",
              "      <td>1566</td>\n",
              "      <td>2228.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>37</td>\n",
              "      <td>749</td>\n",
              "      <td>1149.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>38</td>\n",
              "      <td>974</td>\n",
              "      <td>1475.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>39</td>\n",
              "      <td>562</td>\n",
              "      <td>962.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>40</td>\n",
              "      <td>236</td>\n",
              "      <td>636.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a18e483-8497-42f0-a26d-c511a7e1eab9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4a18e483-8497-42f0-a26d-c511a7e1eab9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4a18e483-8497-42f0-a26d-c511a7e1eab9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4942bedf-2aa2-4b00-9874-8ca5367f4474\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4942bedf-2aa2-4b00-9874-8ca5367f4474')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4942bedf-2aa2-4b00-9874-8ca5367f4474 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_1056adae-a9e5-4380-8f01-343c287a9e85\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('sel_table')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1056adae-a9e5-4380-8f01-343c287a9e85 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('sel_table');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "sel_table",
              "summary": "{\n  \"name\": \"sel_table\",\n  \"rows\": 40,\n  \"fields\": [\n    {\n      \"column\": \"rank\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 1,\n        \"max\": 40,\n        \"num_unique_values\": 40,\n        \"samples\": [\n          20,\n          17,\n          16\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 635,\n        \"min\": 7,\n        \"max\": 1738,\n        \"num_unique_values\": 40,\n        \"samples\": [\n          1516,\n          1486,\n          54\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"wavelength_nm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 755.1285469613086,\n        \"min\": 407.0,\n        \"max\": 2400.0,\n        \"num_unique_values\": 40,\n        \"samples\": [\n          2178.0,\n          2148.0,\n          454.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Self-attention regressor (lightweight) for selected bands\n",
        "# - Small d_model, few heads\n",
        "# - Huber loss, AdamW, cosine LR with warm-up\n",
        "# - Early stopping on val, then refit on train+val\n",
        "# - Seed ensembling for robustness\n",
        "# ============================================================\n",
        "import math, time, numpy as np, torch, torch.nn as nn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# -----------------------\n",
        "# Config\n",
        "# -----------------------\n",
        "CFG = dict(\n",
        "    d_model=32,\n",
        "    nhead=2,\n",
        "    num_layers=2,          # encoder depth\n",
        "    dim_ff=96,\n",
        "    dropout=0.20,\n",
        "    lr=3e-4,\n",
        "    weight_decay=5e-4,\n",
        "    batch_size=64,\n",
        "    max_epochs=200,\n",
        "    patience=40,           # early stopping on val\n",
        "    grad_clip=1.0,\n",
        "    huber_beta=0.5,\n",
        "    warmup_epochs=10,\n",
        "    cosine_min_lr=3e-6,\n",
        "    seeds=[13, 23, 37, 47, 59],   # ensemble\n",
        ")\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# -----------------------\n",
        "# Data scaling (fit on TRAIN ONLY for model selection;\n",
        "# for final training after early-stop, refit on TRAIN+VAL)\n",
        "# -----------------------\n",
        "sc_tr = StandardScaler().fit(Xtr_sel)\n",
        "Xtr_s = sc_tr.transform(Xtr_sel).astype(np.float32)\n",
        "Xva_s = sc_tr.transform(Xva_sel).astype(np.float32)\n",
        "Xte_s = sc_tr.transform(Xte_sel).astype(np.float32)\n",
        "\n",
        "class SpectraDS(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.float32)\n",
        "    def __len__(self): return len(self.y)\n",
        "    def __getitem__(self, i): return self.X[i], self.y[i]\n",
        "\n",
        "tr_loader = DataLoader(SpectraDS(Xtr_s, y_tr), batch_size=CFG[\"batch_size\"], shuffle=True, drop_last=False)\n",
        "va_loader = DataLoader(SpectraDS(Xva_s, y_va), batch_size=CFG[\"batch_size\"], shuffle=False,  drop_last=False)\n",
        "te_loader = DataLoader(SpectraDS(Xte_s, y_te), batch_size=CFG[\"batch_size\"], shuffle=False,  drop_last=False)\n",
        "\n",
        "# -----------------------\n",
        "# Model\n",
        "# -----------------------\n",
        "class PosEnc1D(nn.Module):\n",
        "    def __init__(self, d_model, max_len=4096):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        pos = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n",
        "        div = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0)/d_model))\n",
        "        pe[:, 0::2] = torch.sin(pos * div)\n",
        "        pe[:, 1::2] = torch.cos(pos * div)\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "    def forward(self, x):  # x: (B,L,D)\n",
        "        return x + self.pe[:x.size(1)]\n",
        "\n",
        "class EncoderBlock(nn.Module):\n",
        "    def __init__(self, d_model, nhead, dim_ff, dropout):\n",
        "        super().__init__()\n",
        "        self.attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=True)\n",
        "        self.ffn  = nn.Sequential(\n",
        "            nn.Linear(d_model, dim_ff), nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout), nn.Linear(dim_ff, d_model)\n",
        "        )\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.drop  = nn.Dropout(dropout)\n",
        "    def forward(self, x):\n",
        "        y, _ = self.attn(x, x, x, need_weights=False)\n",
        "        x = self.norm1(x + self.drop(y))\n",
        "        y = self.ffn(x)\n",
        "        x = self.norm2(x + self.drop(y))\n",
        "        return x\n",
        "\n",
        "class SelfTransformerRegressor(nn.Module):\n",
        "    def __init__(self, n_bands, d_model=32, nhead=2, num_layers=2, dim_ff=96, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Linear(1, d_model)\n",
        "        self.pos   = PosEnc1D(d_model, max_len=n_bands)\n",
        "        self.blocks = nn.ModuleList([EncoderBlock(d_model, nhead, dim_ff, dropout) for _ in range(num_layers)])\n",
        "        self.head   = nn.Sequential(\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout), nn.Linear(d_model, 1)\n",
        "        )\n",
        "    def forward(self, x):         # x: (B,L)\n",
        "        z = self.embed(x.unsqueeze(-1))  # (B,L,D)\n",
        "        z = self.pos(z)\n",
        "        for blk in self.blocks:\n",
        "            z = blk(z)\n",
        "        z = z.mean(dim=1)               # global average pooling\n",
        "        return self.head(z).squeeze(-1)\n",
        "\n",
        "# -----------------------\n",
        "# Schedulers & training utils\n",
        "# -----------------------\n",
        "def cosine_with_warmup(epoch, base_lr, warmup, max_epochs, min_lr):\n",
        "    if epoch < warmup:\n",
        "        return base_lr * (epoch + 1) / max(1, warmup)\n",
        "    # cosine from base_lr -> min_lr\n",
        "    t = (epoch - warmup) / max(1, (max_epochs - warmup))\n",
        "    return min_lr + 0.5*(base_lr - min_lr)*(1 + math.cos(math.pi * t))\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_loader(model, loader, crit):\n",
        "    model.eval()\n",
        "    losses, yT, yP = [], [], []\n",
        "    for xb, yb in loader:\n",
        "        xb = xb.to(device); yb = yb.to(device)\n",
        "        pred = model(xb)\n",
        "        losses.append(crit(pred, yb).item())\n",
        "        yT.append(yb.detach().cpu().numpy())\n",
        "        yP.append(pred.detach().cpu().numpy())\n",
        "    yT = np.concatenate(yT); yP = np.concatenate(yP)\n",
        "    rmse = float(np.sqrt(np.mean((yT - yP)**2)))\n",
        "    ss_res = float(np.sum((yT - yP)**2))\n",
        "    ss_tot = float(np.sum((yT - yT.mean())**2) + 1e-12)\n",
        "    r2     = 1.0 - ss_res/ss_tot\n",
        "    return rmse, r2, yP\n",
        "\n",
        "def train_one_seed(seed, verbose_every=5):\n",
        "    torch.manual_seed(seed); np.random.seed(seed)\n",
        "\n",
        "    # ----- build model -----\n",
        "    model = SelfTransformerRegressor(\n",
        "        n_bands=Xtr_s.shape[1],\n",
        "        d_model=CFG[\"d_model\"], nhead=CFG[\"nhead\"],\n",
        "        num_layers=CFG[\"num_layers\"], dim_ff=CFG[\"dim_ff\"], dropout=CFG[\"dropout\"]\n",
        "    ).to(device)\n",
        "\n",
        "    opt  = torch.optim.AdamW(model.parameters(), lr=CFG[\"lr\"], weight_decay=CFG[\"weight_decay\"])\n",
        "    crit = nn.SmoothL1Loss(beta=CFG[\"huber_beta\"])  # Huber\n",
        "\n",
        "    best_val = float(\"inf\")\n",
        "    best_state = None\n",
        "    wait = 0\n",
        "\n",
        "    # ----- training with per-epoch print -----\n",
        "    for ep in range(1, CFG[\"max_epochs\"]+1):\n",
        "        # cosine LR with warmup\n",
        "        for pg in opt.param_groups:\n",
        "            pg[\"lr\"] = cosine_with_warmup(ep-1, CFG[\"lr\"], CFG[\"warmup_epochs\"], CFG[\"max_epochs\"], CFG[\"cosine_min_lr\"])\n",
        "\n",
        "        # train one epoch\n",
        "        model.train()\n",
        "        train_mse_batches = []\n",
        "        for xb, yb in tr_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            pred = model(xb)\n",
        "            loss = crit(pred, yb)\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), CFG[\"grad_clip\"])\n",
        "            opt.step()\n",
        "            with torch.no_grad():\n",
        "                train_mse_batches.append(torch.mean((pred - yb)**2).item())\n",
        "        tr_rmse = float(np.sqrt(np.mean(train_mse_batches)))\n",
        "\n",
        "        # validate\n",
        "        val_rmse, val_r2, _ = eval_loader(model, va_loader, crit)\n",
        "\n",
        "        # print (your exact style)\n",
        "        if ep == 1 or ep % verbose_every == 0:\n",
        "            print(f\"Epoch {ep:03d} | trainRMSE={tr_rmse:.3f} | valRMSE={val_rmse:.3f} | valR²={val_r2:.3f}\")\n",
        "\n",
        "        # early stopping\n",
        "        if val_rmse < best_val - 1e-6:\n",
        "            best_val = val_rmse; wait = 0\n",
        "            best_state = {k: v.detach().cpu() for k, v in model.state_dict().items()}\n",
        "        else:\n",
        "            wait += 1\n",
        "            if wait >= CFG[\"patience\"]:\n",
        "                break\n",
        "\n",
        "    # load best weights\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state)\n",
        "\n",
        "    # ----- refit on TRAIN+VAL for a fixed short schedule -----\n",
        "    sc_tv = StandardScaler().fit(np.vstack([Xtr_sel, Xva_sel]))\n",
        "    Xtv_s = sc_tv.transform(np.vstack([Xtr_sel, Xva_sel])).astype(np.float32)\n",
        "    y_tv  = np.concatenate([y_tr, y_va]).astype(np.float32)\n",
        "\n",
        "    tv_loader = DataLoader(SpectraDS(Xtv_s, y_tv), batch_size=CFG[\"batch_size\"], shuffle=True, drop_last=False)\n",
        "    te_loader_refit = DataLoader(SpectraDS(sc_tv.transform(Xte_sel).astype(np.float32), y_te.astype(np.float32)),\n",
        "                                 batch_size=CFG[\"batch_size\"], shuffle=False, drop_last=False)\n",
        "\n",
        "    torch.manual_seed(seed)\n",
        "    model2 = SelfTransformerRegressor(\n",
        "        n_bands=Xtv_s.shape[1],\n",
        "        d_model=CFG[\"d_model\"], nhead=CFG[\"nhead\"],\n",
        "        num_layers=CFG[\"num_layers\"], dim_ff=CFG[\"dim_ff\"], dropout=CFG[\"dropout\"]\n",
        "    ).to(device)\n",
        "\n",
        "    opt2  = torch.optim.AdamW(model2.parameters(), lr=CFG[\"lr\"], weight_decay=CFG[\"weight_decay\"])\n",
        "    crit2 = nn.SmoothL1Loss(beta=CFG[\"huber_beta\"])\n",
        "\n",
        "    refit_epochs = min(int(1.2*CFG[\"patience\"]), int(0.6*CFG[\"max_epochs\"]))\n",
        "    for ep in range(1, refit_epochs+1):\n",
        "        for pg in opt2.param_groups:\n",
        "            pg[\"lr\"] = cosine_with_warmup(ep-1, CFG[\"lr\"], CFG[\"warmup_epochs\"], refit_epochs, CFG[\"cosine_min_lr\"])\n",
        "        model2.train()\n",
        "        for xb, yb in tv_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            opt2.zero_grad(set_to_none=True)\n",
        "            pred = model2(xb)\n",
        "            loss = crit2(pred, yb)\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(model2.parameters(), CFG[\"grad_clip\"])\n",
        "            opt2.step()\n",
        "\n",
        "    # ----- test -----\n",
        "    te_rmse, te_r2, te_pred = eval_loader(model2, te_loader_refit, crit2)\n",
        "    return te_pred, te_rmse, te_r2\n",
        "\n",
        "# -----------------------\n",
        "# Train multiple seeds and ensemble predictions\n",
        "# -----------------------\n",
        "all_preds = []\n",
        "seed_scores = []\n",
        "for sd in CFG[\"seeds\"]:\n",
        "    pred, rm, r2 = train_one_seed(sd)\n",
        "    all_preds.append(pred.reshape(-1, 1))\n",
        "    seed_scores.append((sd, rm, r2))\n",
        "\n",
        "ens_pred = np.mean(np.hstack(all_preds), axis=1)\n",
        "ens_rmse = float(np.sqrt(np.mean((y_te - ens_pred)**2)))\n",
        "ss_res = float(np.sum((y_te - ens_pred)**2))\n",
        "ss_tot = float(np.sum((y_te - y_te.mean())**2) + 1e-12)\n",
        "ens_r2  = 1.0 - ss_res/ss_tot\n",
        "\n",
        "print(\"\\nPer-seed test scores:\")\n",
        "for sd, rm, r2 in seed_scores:\n",
        "    print(f\"  seed {sd:>2} → RMSE={rm:.3f} | R²={r2:.3f}\")\n",
        "print(f\"\\nEnsemble  → RMSE={ens_rmse:.3f} | R²={ens_r2:.3f}\")\n",
        "\n",
        "# Optional: scatter plot (requires matplotlib)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(4.8,4.2))\n",
        "plt.scatter(y_te, ens_pred, s=16)\n",
        "mn, mx = min(y_te.min(), ens_pred.min()), max(y_te.max(), ens_pred.max())\n",
        "plt.plot([mn,mx],[mn,mx],'k--',lw=1)\n",
        "plt.xlabel(\"True Nmass_O\"); plt.ylabel(\"Predicted Nmass_O\"); plt.title(\"Self-Transformer (ensemble) — Test\")\n",
        "plt.tight_layout(); plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zn0t1SAFJIS9",
        "outputId": "dc341670-77a3-4bbb-e0aa-a38f9109a5df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 001 | trainRMSE=29.263 | valRMSE=28.324 | valR²=-12.364\n",
            "Epoch 005 | trainRMSE=8.937 | valRMSE=7.511 | valR²=0.060\n",
            "Epoch 010 | trainRMSE=6.626 | valRMSE=4.870 | valR²=0.605\n",
            "Epoch 015 | trainRMSE=6.025 | valRMSE=4.666 | valR²=0.637\n",
            "Epoch 020 | trainRMSE=6.177 | valRMSE=4.639 | valR²=0.642\n",
            "Epoch 025 | trainRMSE=6.045 | valRMSE=4.612 | valR²=0.646\n",
            "Epoch 030 | trainRMSE=5.911 | valRMSE=4.884 | valR²=0.603\n",
            "Epoch 035 | trainRMSE=5.947 | valRMSE=4.695 | valR²=0.633\n",
            "Epoch 040 | trainRMSE=5.687 | valRMSE=4.293 | valR²=0.693\n",
            "Epoch 045 | trainRMSE=5.742 | valRMSE=4.336 | valR²=0.687\n",
            "Epoch 050 | trainRMSE=5.645 | valRMSE=4.272 | valR²=0.696\n",
            "Epoch 055 | trainRMSE=5.543 | valRMSE=4.284 | valR²=0.694\n",
            "Epoch 060 | trainRMSE=5.617 | valRMSE=4.352 | valR²=0.684\n",
            "Epoch 065 | trainRMSE=5.601 | valRMSE=4.355 | valR²=0.684\n",
            "Epoch 070 | trainRMSE=5.722 | valRMSE=4.165 | valR²=0.711\n",
            "Epoch 075 | trainRMSE=5.606 | valRMSE=4.287 | valR²=0.694\n",
            "Epoch 080 | trainRMSE=5.403 | valRMSE=4.153 | valR²=0.713\n",
            "Epoch 085 | trainRMSE=5.458 | valRMSE=4.221 | valR²=0.703\n",
            "Epoch 090 | trainRMSE=5.540 | valRMSE=4.477 | valR²=0.666\n",
            "Epoch 095 | trainRMSE=5.492 | valRMSE=4.161 | valR²=0.712\n",
            "Epoch 100 | trainRMSE=5.441 | valRMSE=4.177 | valR²=0.709\n",
            "Epoch 105 | trainRMSE=5.466 | valRMSE=4.160 | valR²=0.712\n",
            "Epoch 110 | trainRMSE=5.415 | valRMSE=4.526 | valR²=0.659\n",
            "Epoch 115 | trainRMSE=5.301 | valRMSE=4.183 | valR²=0.709\n",
            "Epoch 120 | trainRMSE=5.345 | valRMSE=4.016 | valR²=0.731\n",
            "Epoch 125 | trainRMSE=5.254 | valRMSE=4.084 | valR²=0.722\n",
            "Epoch 130 | trainRMSE=5.228 | valRMSE=4.073 | valR²=0.724\n",
            "Epoch 135 | trainRMSE=5.254 | valRMSE=4.051 | valR²=0.727\n",
            "Epoch 140 | trainRMSE=5.235 | valRMSE=4.161 | valR²=0.712\n",
            "Epoch 145 | trainRMSE=5.245 | valRMSE=4.137 | valR²=0.715\n",
            "Epoch 150 | trainRMSE=5.136 | valRMSE=4.178 | valR²=0.709\n",
            "Epoch 155 | trainRMSE=5.260 | valRMSE=4.168 | valR²=0.711\n",
            "Epoch 160 | trainRMSE=5.137 | valRMSE=4.126 | valR²=0.716\n",
            "Epoch 165 | trainRMSE=5.251 | valRMSE=4.082 | valR²=0.722\n",
            "Epoch 170 | trainRMSE=5.296 | valRMSE=4.072 | valR²=0.724\n",
            "Epoch 175 | trainRMSE=5.155 | valRMSE=4.098 | valR²=0.720\n",
            "Epoch 001 | trainRMSE=28.606 | valRMSE=27.172 | valR²=-11.298\n",
            "Epoch 005 | trainRMSE=7.883 | valRMSE=7.062 | valR²=0.169\n",
            "Epoch 010 | trainRMSE=6.088 | valRMSE=4.647 | valR²=0.640\n",
            "Epoch 015 | trainRMSE=5.814 | valRMSE=4.546 | valR²=0.656\n",
            "Epoch 020 | trainRMSE=5.760 | valRMSE=4.640 | valR²=0.641\n",
            "Epoch 025 | trainRMSE=5.598 | valRMSE=4.442 | valR²=0.671\n",
            "Epoch 030 | trainRMSE=5.517 | valRMSE=4.421 | valR²=0.674\n",
            "Epoch 035 | trainRMSE=5.636 | valRMSE=4.723 | valR²=0.628\n",
            "Epoch 040 | trainRMSE=5.299 | valRMSE=4.377 | valR²=0.681\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2773743344.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0mseed_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"seeds\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0mall_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0mseed_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2773743344.py\u001b[0m in \u001b[0;36mtrain_one_seed\u001b[0;34m(seed, verbose_every)\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"grad_clip\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0mtrain_mse_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    514\u001b[0m                             )\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    245\u001b[0m             )\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    248\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mmaybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdisabled_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_fallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    947\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m     func(\n\u001b[0m\u001b[1;32m    950\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[0m\n\u001b[1;32m    531\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}